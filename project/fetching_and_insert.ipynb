{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216d3799-4d1d-494a-8a1f-48de97be3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install docling pymilvus ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d975362d-3b66-40cd-9420-89ca691a4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install \"pymilvus[model]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d365df-9192-427c-9879-279068fba56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from pymilvus import MilvusClient\n",
    "from pymilvus import connections\n",
    "from pymilvus import model\n",
    "from docling.chunking import HybridChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40e0532-bbae-4c47-b989-191cc174181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MilvusClient(\"http://vectordb-milvus.milvus.svc.cluster.local:19530\", user=\"root\", password=\"Milvus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a312c166-766c-4698-8409-eeb01f6b4204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Collection  openshift_ai_documentation\n"
     ]
    }
   ],
   "source": [
    "# Variable for collection name\n",
    "collection_name = \"openshift_ai_documentation\"\n",
    "\n",
    "# Delete collection if the collection exists\n",
    "if client.has_collection(collection_name=collection_name):\n",
    "    print(\"going to delete \", collection_name)\n",
    "    client.drop_collection(collection_name=collection_name)\n",
    "\n",
    "# Create collection\n",
    "print(\"Creating Collection \", collection_name)   \n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    dimension=768,  # The vectors we will use in this demo has 768 dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152c7b23-04d6-407d-afa8-23053c513661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bbbd7dd0ec4fefab2204f7a136aef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbda7079bdd1477dab7647f532b6be8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/827 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c63643af4e6493590a715d17278a44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc06fb166e94538abdfb7a976c8b07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ed550323554bf884e8be661de33949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/245 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f04eb2bddf47b896075d362a5d3eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/46.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define embedding model\n",
    "embedding_fn = model.DefaultEmbeddingFunction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033492f-170c-4548-8dc5-6947a1d1e317",
   "metadata": {},
   "source": [
    "# Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81bcde1-8c3e-445f-844d-d69b82e029c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "def get_file_name_from_url(url):\n",
    "    # Parse the URL to extract the path\n",
    "    parsed_url = urlparse(url)\n",
    "    # Extract the file name from the path\n",
    "    file_name = parsed_url.path.split('/')[-1]\n",
    "    \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b4d3aa-df53-4e82-9368-42c567e97d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_from_filename(filename):\n",
    "    metadata = filename.split(\"-\")\n",
    "    return {\n",
    "            \"product_name\": metadata[0],\n",
    "            \"version\": metadata[2],\n",
    "            \"section\": metadata[3],\n",
    "            \"language\": metadata[4]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd51e96a-5aa2-4486-8f56-2e355f013707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAUTION: MAX FILE URLS EQUALS 100\n",
      "Handling 0. file with metadata: {'product_name': 'Red_Hat_OpenShift_AI_Self', 'version': '2.16', 'section': 'Monitoring_data_science_models', 'language': 'en'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling 1. file with metadata: {'product_name': 'Red_Hat_OpenShift_AI_Self', 'version': '2.16', 'section': 'Release_notes', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "base_url=\"https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/2.16/pdf/\"\n",
    "source_urls=[base_url + \"monitoring_data_science_models/Red_Hat_OpenShift_AI_Self-Managed-2.16-Monitoring_data_science_models-en-US.pdf\",\n",
    "              base_url + \"release_notes/Red_Hat_OpenShift_AI_Self-Managed-2.16-Release_notes-en-US.pdf\",]\n",
    "\n",
    "chunker = HybridChunker(tokenizer=\"BAAI/bge-small-en-v1.5\")\n",
    "converter = DocumentConverter()\n",
    "\n",
    "print(\"CAUTION: MAX FILE URLS EQUALS 100\")\n",
    "\n",
    "## Define Empty Vector Array\n",
    "vectors = []\n",
    "\n",
    "for file_index,file in enumerate(source_urls):\n",
    "    ## Retrieve metadata from one file\n",
    "    metadata = get_metadata_from_filename(get_file_name_from_url(file))\n",
    "    print(f\"Handling file {file_index} with metadata: {metadata}\")\n",
    "    \n",
    "    ## Parse document from source chunk it\n",
    "    converted_source_file = converter.convert(file)\n",
    "    document = converted_source_file.document\n",
    "    chunk_iter = chunker.chunk(document)\n",
    "    ## Create chunk_list with the parts of the document\n",
    "    chunk_list = list(chunk_iter)\n",
    "\n",
    "\n",
    "    chunk_vectors = embedding_fn.encode_documents([chunk.text for chunk in chunk_list])\n",
    "\n",
    "\n",
    "    for i, chunk in enumerate(chunk_list):\n",
    "        vectors.append({\n",
    "            \"id\": int(str(file_index * 100) + str(i)), \n",
    "            \"product_name\": metadata.get(\"product_name\", \"null\"),\n",
    "            \"version\": metadata.get(\"version\", \"null\"),\n",
    "            \"section\": metadata.get(\"section\", \"null\"),\n",
    "            \"language\": metadata.get(\"language\", \"null\"),\n",
    "            \"vector\": chunk_vectors[i] , \n",
    "            \"text\": chunk.text,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647cb3e-9750-42d8-a8c1-16c85467e51d",
   "metadata": {},
   "source": [
    "# Insert File Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbd0e93f-8fd7-4a01-b1b3-90be628a56de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_count': 286, 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 10010, 10011, 10012, 10013, 10014, 10015, 10016, 10017, 10018, 10019, 10020, 10021, 10022, 10023, 10024, 10025, 10026, 10027, 10028, 10029, 10030, 10031, 10032, 10033, 10034, 10035, 10036, 10037, 10038, 10039, 10040, 10041, 10042, 10043, 10044, 10045, 10046, 10047, 10048, 10049, 10050, 10051, 10052, 10053, 10054, 10055, 10056, 10057, 10058, 10059, 10060, 10061, 10062, 10063, 10064, 10065, 10066, 10067, 10068, 10069, 10070, 10071, 10072, 10073, 10074, 10075, 10076, 10077, 10078, 10079, 10080, 10081, 10082, 10083, 10084, 10085, 10086, 10087, 10088, 10089, 10090, 10091, 10092, 10093, 10094, 10095, 10096, 10097, 10098, 10099, 100100, 100101, 100102, 100103, 100104, 100105, 100106, 100107, 100108, 100109, 100110, 100111, 100112, 100113, 100114, 100115, 100116, 100117, 100118, 100119, 100120, 100121, 100122, 100123, 100124, 100125, 100126, 100127, 100128, 100129, 100130, 100131, 100132, 100133, 100134, 100135, 100136, 100137, 100138, 100139, 100140, 100141, 100142, 100143, 100144, 100145, 100146, 100147, 100148, 100149, 100150, 100151, 100152, 100153, 100154, 100155, 100156, 100157, 100158, 100159, 100160, 100161, 100162, 100163, 100164, 100165, 100166, 100167, 100168, 100169, 100170, 100171, 100172, 100173]}\n"
     ]
    }
   ],
   "source": [
    "# Insert data\n",
    "res = client.insert(collection_name=collection_name, data=vectors)\n",
    "\n",
    "# Check Output\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb61a08-bda0-4e34-8287-24fd3a0be4d2",
   "metadata": {},
   "source": [
    "# Query Milvus with search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db256399-dbae-422d-9ec0-7e9cf43aae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 27, 'distance': 0.5015285611152649, 'entity': {'text': 'Install the TrustyAI service on a data science project to provide access to its features for all models deployed within that project. An instance of the TrustyAI service is required for each data science project, or namespace, that contains models that the data scientists want to monitor.', 'version': '2.16', 'section': 'Monitoring_data_science_models', 'product_name': 'Red_Hat_OpenShift_AI_Self'}}\n",
      "{'id': 17, 'distance': 0.48790931701660156, 'entity': {'text': 'To allow your data scientists to use model monitoring with TrustyAI, you must enable the TrustyAI component in OpenShift AI.', 'version': '2.16', 'section': 'Monitoring_data_science_models', 'product_name': 'Red_Hat_OpenShift_AI_Self'}}\n",
      "{'id': 60, 'distance': 0.48153039813041687, 'entity': {'text': 'You are familiar with the bias metrics that OpenShift AI supports  and how to interpret them.\\nYou are familiar with the specific data set schema and understand the names and meanings of the inputs and outputs.\\nYour OpenShift cluster administrator added you as a user to the OpenShift cluster and has installed the TrustyAI service for the data science project that contains the deployed models.\\nYou set up TrustyAI for your data science project, as described in Setting up TrustyAI for your project.', 'version': '2.16', 'section': 'Monitoring_data_science_models', 'product_name': 'Red_Hat_OpenShift_AI_Self'}}\n"
     ]
    }
   ],
   "source": [
    "# Define vector question\n",
    "question_vectors = embedding_fn.encode_queries([\"What is trusty AI used for?\"])\n",
    "\n",
    "# Search data using a Vector base approach with questions and relationships\n",
    "res = client.search(\n",
    "    collection_name=collection_name,  \n",
    "    data=question_vectors,  # Do vector comparison based on search query\n",
    "    limit=5,  \n",
    "    filter=\"version == '2.16'\", # Filter additionally based on metadata\n",
    "    output_fields=[\"text\", \"version\", \"section\", \"product_name\"],  \n",
    ")\n",
    "\n",
    "for entry in res[0]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2451ed-7836-4735-9382-d7cc79cdb9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
